{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1wozGeLJNJRYTvrQpXpzSzyg3jPD1Y8ty","timestamp":1674803708814}],"collapsed_sections":["muDG77MVy7G9"],"mount_file_id":"1y1jRx2ces1uWFv9DJbtkJMCjvNsDi1Yp","authorship_tag":"ABX9TyMdbgvesT+l+irCtZAybyAd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"8009f804cc3c45b7871d3ed29ab7bf90":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_784e7d36ee9440db98217582ddb4e34d","IPY_MODEL_eb24ab24cc074b298f6df57896bdea5c","IPY_MODEL_2f3a1b9ec9f144c18d867dc8c1288b4b"],"layout":"IPY_MODEL_1dac2965045a49f6ac6e78fc5cfe1142"}},"784e7d36ee9440db98217582ddb4e34d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16186d3ce0af4d7396f2f7765aa1a277","placeholder":"​","style":"IPY_MODEL_92ee634881b043aa8562f7a5410ac54f","value":"100%"}},"eb24ab24cc074b298f6df57896bdea5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f207ea0ed874b0983c3ab06c01c6161","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3092d08b6a14d1a9ae5a8f48376d9be","value":1}},"2f3a1b9ec9f144c18d867dc8c1288b4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1f37c86957e4fabb5ceeeb032bf0750","placeholder":"​","style":"IPY_MODEL_93367cca03034777bfc9ceba20f49832","value":" 1/1 [00:00&lt;00:00, 74.43it/s]"}},"1dac2965045a49f6ac6e78fc5cfe1142":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16186d3ce0af4d7396f2f7765aa1a277":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92ee634881b043aa8562f7a5410ac54f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f207ea0ed874b0983c3ab06c01c6161":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3092d08b6a14d1a9ae5a8f48376d9be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d1f37c86957e4fabb5ceeeb032bf0750":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93367cca03034777bfc9ceba20f49832":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ffb904ec46d4f3a9236ec21424b5e6e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c47ef57b00b4171bc5a7edbff32f79d","IPY_MODEL_2e9a09095b714a6a8f9c9475c1000049","IPY_MODEL_12897725c18a42d7bfd24a6de9bb4eb5"],"layout":"IPY_MODEL_1f0386398fb7448d8514503fff16ce8a"}},"7c47ef57b00b4171bc5a7edbff32f79d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed212207d09e49b797f63ce1baa119c9","placeholder":"​","style":"IPY_MODEL_ded278b9c5734363b58e347e504260c6","value":"100%"}},"2e9a09095b714a6a8f9c9475c1000049":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50233955d241449f86a03ef7bcaa4f41","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_253cff73e91b40b1a0e4924c4839fbd4","value":1}},"12897725c18a42d7bfd24a6de9bb4eb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_058f6cb2ee594c2dbe88db9c61e71336","placeholder":"​","style":"IPY_MODEL_5adada33dbc4467a98736167df413b2f","value":" 1/1 [00:00&lt;00:00,  9.63ba/s]"}},"1f0386398fb7448d8514503fff16ce8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed212207d09e49b797f63ce1baa119c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ded278b9c5734363b58e347e504260c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50233955d241449f86a03ef7bcaa4f41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"253cff73e91b40b1a0e4924c4839fbd4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"058f6cb2ee594c2dbe88db9c61e71336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5adada33dbc4467a98736167df413b2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28c9ce02fd314134bcb2e2aff474f8f4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a65771652cad4ec0880afa0155493716","IPY_MODEL_630cd8402e844904bf6866fb0c301374","IPY_MODEL_6eef9cb0993e4c51afa0f68f32954a80"],"layout":"IPY_MODEL_14bc044df1d54e15b07e5ae14be168e3"}},"a65771652cad4ec0880afa0155493716":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a3393c9f09c42669269d7e7a1e5d792","placeholder":"​","style":"IPY_MODEL_5a84ed738c204215b079ec803c0b7a9e","value":"100%"}},"630cd8402e844904bf6866fb0c301374":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_56794b81075c471d88ebfb75d579fb90","max":24,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a08baf0ab2d415a9b601d85a3b9ce5d","value":24}},"6eef9cb0993e4c51afa0f68f32954a80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be39042aa40a4e458010acbc6d9dadfe","placeholder":"​","style":"IPY_MODEL_94ec3de96787413087a6b33484871fc0","value":" 24/24 [00:01&lt;00:00, 27.35it/s]"}},"14bc044df1d54e15b07e5ae14be168e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a3393c9f09c42669269d7e7a1e5d792":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a84ed738c204215b079ec803c0b7a9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56794b81075c471d88ebfb75d579fb90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a08baf0ab2d415a9b601d85a3b9ce5d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be39042aa40a4e458010acbc6d9dadfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94ec3de96787413087a6b33484871fc0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Setup File"],"metadata":{"id":"SAw-AaN9zB60"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8Wz-z8T4Nvh","executionInfo":{"status":"ok","timestamp":1676583229837,"user_tz":-60,"elapsed":58131,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}},"outputId":"7a725b49-9124-4fa6-e538-2cd6a545c39d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install nltk --quiet\n","!pip install transformers --quiet\n","!pip install datasets --quiet\n","!pip install evaluate --quiet\n","!pip install sentencepiece --quiet\n","!pip install accelerate --quiet\n","!pip install rouge_score --quiet\n","!pip install bert_score --quiet\n","!pip install torchvision --quiet\n","!pip install tensorboard --quiet"]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/MscThesis/Evaluation_code/Bartscore.py /content"],"metadata":{"id":"CmEouM1_-LkS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pickle\n","import pandas as pd\n","import numpy as np\n","import re\n","import torch \n","import nltk\n","\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, pipeline,  EarlyStoppingCallback, DataCollatorForSeq2Seq, Trainer\n","from transformers import MT5ForConditionalGeneration, T5Tokenizer, T5ForConditionalGeneration, MT5TokenizerFast, is_torch_tpu_available, logging\n","\n","import datasets\n","import evaluate\n","import accelerate\n","\n","import Bartscore as bartscore \n","import gc\n","import json\n","from ast import literal_eval"],"metadata":{"id":"fETBxnHs4i_q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FXFh1oOZe5VV","executionInfo":{"status":"ok","timestamp":1676583238177,"user_tz":-60,"elapsed":5,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}},"outputId":"93930e0a-7379-4a9d-b93c-c8f1937e5ab3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["# Set Parameters"],"metadata":{"id":"-VBVaoB1zGOI"}},{"cell_type":"code","source":["# Define Parameters\n","FLAGS = {}\n","FLAGS['model_name'] = \"google/mt5-base\" \n","FLAGS['max_token_length_preprocessing'] = 256\n","FLAGS['early_stopping_patience'] = 3\n","FLAGS['model_save_total_limit'] = 4\n","FLAGS['training_optimizer'] = \"adafactor\"\n","FLAGS['batch_size'] = 16\n","FLAGS['gradient_accumulation_steps'] = 2\n","FLAGS['learning_rate'] = 5e-05\n","FLAGS['num_epochs'] = 200\n","FLAGS['training_strategy'] = 'epoch'\n","FLAGS['generation_num_beams'] = 5\n","FLAGS['generation_max_length'] = 100\n","FLAGS['data_location'] = \"/content/drive/MyDrive/MscThesis/Data/Elongated_test_subset/Improved Parent Testing/\"\n","FLAGS['drive_path'] = \"/content/drive/MyDrive/MscThesis\"\n","FLAGS['mixed_precision'] = False # it seems that fp16 results in no learning (e.g. training loss of 0.000 andvalidation loss of nan)\n","FLAGS['model_iteration'] = 'google_mt5-base/'\n","FLAGS['path_model_name'] = \"google_mt5-base/\"\n","FLAGS['saved_model_path'] = '/content/drive/MyDrive/MscThesis/Models/google_mt5-base/Elongated_best_model/'"],"metadata":{"id":"65-21XHa4mzv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Full Training and Evaluation Pipeline"],"metadata":{"id":"shtM214YzH2r"}},{"cell_type":"code","source":["############################################################################## Begin Environment Setup ######################################################################################\n","\n","def ensure_cuda_compatability():\n","    print(f'Torch version: {torch.__version__}')\n","    print(f'Cuda version: {torch.version.cuda}')\n","    print(f'Cudnn version: {torch.backends.cudnn.version()}')\n","    print(f'Is cuda available: {torch.cuda.is_available()}')\n","    print(f'Number of cuda devices: {torch.cuda.device_count()}')\n","    print(f'Current default device: {torch.cuda.current_device()}')\n","    print(f'First cuda device: {torch.cuda.device(0)}')\n","    print(f'Name of the first cuda device: {torch.cuda.get_device_name(0)}\\n\\n')\n","    torch.backends.cuda.matmul.allow_tf32 = True\n","    torch.backends.cudnn.allow_tf32 = True\n","    #Ensure we are really working with full GPU capacity\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","\n","############################################################################## End Environment Setup ######################################################################################\n","\n","############################################################################## Begin Model and Dataset Setup ######################################################################################\n","\n","def preprocess_model(model_name):\n","    \"\"\"\n","    Setup the model and tokenizer for preprocessing. This will be a pre-trained model collected from huggingface\n","    \"\"\"\n","    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    #tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n","    #BartTokenizerFast with add_prefix_space=True\n","\n","    print('LOGGING: preprocess_model DONE \\n')\n","    return model, tokenizer\n","\n","\n","def load_CACAPO_data():\n","    \"\"\"\n","    This function retrieves the csv files and creates a dataset\n","    \"\"\"\n","    return datasets.load_dataset(FLAGS['data_location'], data_files={\"test\": \"Test.csv\"})\n","\n","\n","def preprocess_data(data):\n","    \"\"\"\n","    Tokenize the data\n","    \"\"\"\n","    max_length = FLAGS['max_token_length_preprocessing']\n","    RDFs = data[\"input\"]\n","    texts = data[\"output\"]\n","\n","    ## When converting a pandas df to csv (used for loading dataset), a list of lists can transform to a long string\n","    ## Here we convert it back with literal_eval\n","\n","    for rdf_iteration, rdf in enumerate(RDFs):\n","        RDFs[rdf_iteration] = literal_eval(rdf)\n","\n","    model_inputs = tokenizer(RDFs, truncation=True, padding='max_length', return_tensors='pt',  max_length=max_length, is_split_into_words=True)\n","    \n","    with tokenizer.as_target_tokenizer():\n","        target_texts = tokenizer(texts, padding='max_length', truncation=True, return_tensors='pt',  max_length=max_length).input_ids\n","\n","    model_inputs[\"labels\"] = target_texts\n","\n","    return model_inputs\n","\n","\n","def transform_datasets(dataset):\n","    \"\"\"\n","    After loading in and creating the initial dataset, the text data is transformed, by tokenizing the input and output texts. The initial dataset is also split into train,val,test for training use.\n","    NOTE That the test set will not be preprocessed here yet, this will be done in a different function\n","    \"\"\"\n","\n","    train_ds = dataset[\"train\"]\n","    val_ds = dataset[\"dev\"]\n","    test_ds = dataset[\"test\"]\n","\n","    # to use the actual articles for evaluation\n","    true_articles_test = test_ds['output']\n","    # The Parent Metric requires the original RDFs\n","    test_rdf_input = test_ds['input']\n","\n","\n","    ## Process the data in batches\n","    train_ds = train_ds.map(preprocess_data, batched=True, remove_columns=dataset[\"train\"].column_names)\n","    val_ds = val_ds.map(preprocess_data, batched=True, remove_columns=dataset[\"dev\"].column_names)\n","    test_ds = test_ds.map(preprocess_data, batched=True, remove_columns=dataset[\"test\"].column_names)\n","\n","    # transform the datasets into torch sensors, as the model will expect this format\n","    train_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels']) \n","    val_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","    test_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","\n","    print('LOGGING: transform_datasets DONE \\n')\n","\n","    return train_ds, val_ds, test_ds, true_articles_test, test_rdf_input\n","\n","############################################################################## End Model and Dataset Setup ######################################################################################\n","\n","############################################################################## Begin Evaluation Setup######################################################################################\n","\n","\n","def load_eval_metrics():\n","    \"\"\"\n","    Loads in all metrics that will be used later on during evaluation. This is seperated to not load in the metrics a dozen of times during training.\n","    \"\"\"\n","    bleu = datasets.load_metric(\"bleu\")\n","    rouge = evaluate.load('rouge')\n","    meteor = evaluate.load('meteor')\n","    perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n","    bertscore = evaluate.load(\"bertscore\")\n","    bart_scorer = bartscore.BARTScorer(device = 'cuda', checkpoint='facebook/bart-base') \n","\n","    print('LOGGING: load_eval_metrics DONE \\n')\n","\n","    return bleu, rouge, meteor, perplexity, bertscore, bart_scorer\n","\n","\n","def postprocess_text(preds, labels):\n","    \"\"\"\n","    Supplementary Method called in decode_text.\n","\n","    Returns list of split decoded labels and predictions for evaluation\n","    \"\"\"\n","    preds = [pred.split() for pred in preds]\n","    labels = [[label.split()] for label in labels]\n","    return preds, labels\n","\n","\n","\n","def decode_text(predictions, labels):\n","    \"\"\"\n","    Supplementary Method called in compute_metrics.\n","\n","    Returns decoded labels and predictions for evaluation\n","    \"\"\"\n","    if isinstance(predictions, tuple):\n","            predictions = predictions[0]\n","\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    \n","    return decoded_preds, decoded_labels\n","\n","############################################################################## End Evaluation Setup######################################################################################\n","\n","############################################################################## Begin Evaluation######################################################################################\n","\n","def evaluate_texts(decoded_preds, decoded_labels):\n","    \"\"\"\n","    Calculates metrics given a list of decoded predictions and decoded labels\n","    \"\"\"\n","    #post_process for BLEU\n","    blue_preds, blue_labels = postprocess_text(decoded_preds,  decoded_labels)\n","\n","    # setup metrics for use\n","    bleu, rouge, meteor,perplexity, bertscore, bart_scorer = load_eval_metrics()\n","\n","    #Calculate the metrics\n","    print(f'\\n LOGGING: Calculating Blue')\n","    bleu_output = bleu.compute(predictions=blue_preds, references=blue_labels)\n","    print(f'\\n LOGGING: Calculating Rouge')\n","    rouge_output = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n","    print(f'\\n LOGGING: Calculating Meteor')\n","    meteor_output = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n","    print(f'\\n LOGGING: Calculating Perplexity')\n","    perp_output = perplexity.compute(predictions=decoded_preds, model_id='gpt2')\n","    print(f'\\n LOGGING: Calculating Bertscore')\n","    bertscore_output = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")\n","    print(f'\\n LOGGING: Calculating Bartscore')\n","    bart_scores_output = bart_scorer.score(srcs=decoded_preds, tgts=decoded_labels, batch_size=FLAGS['batch_size'])\n","\n","    print(f'\\n LOGGING: Done calculations')\n","\n","    return bleu_output, rouge_output, meteor_output, perp_output, bertscore_output, bart_scores_output\n","\n","\n","def compute_metrics(pred):\n","    \"\"\"\"\n","    Metrics to be evaluated during training and validation\n","    Metrics used: BLEU, ROUGE, METEOR, Bertscore, BARTScore\n","    \"\"\"\n","    # decode the predictions and labels for eval\n","    predictions, labels = pred\n","    decoded_preds, decoded_labels = decode_text(predictions, labels)\n","\n","    bleu_output, rouge_output, meteor_output, perp_output, bertscore_output, bart_scores_output = evaluate_texts(decoded_preds, decoded_labels)\n","    \n","    ## Huggingsface trainer requires a dict if multiple metrics are used\n","    evaluation_results = {\"blue_output\": bleu_output, \"rouge_output\": rouge_output, \"meteor_results\": meteor_output, \"perp_output\": perp_output, \n","                          \"bertscore_output\": bertscore_output, \"bart_scores_output\": bart_scores_output}  \n","    \n","    # Tensorboard doesn't like the dict format of our calculated methods, so we write them to a file so that we can create our own figures later on.\n","    logging_for_graphs_path = f\"{FLAGS['drive_path']}GraphMetricLogging/{path_model_name}_metrics.txt\"\n","    \n","    # if the file doesn't exist yet, create it and write first evaluation results to it\n","    if not os.path.exists(logging_for_graphs_path):\n","        with open(logging_for_graphs_path, 'w', encoding='utf-8') as logging_creation:\n","            logging_creation.write(f'{evaluation_results} \\n')\n","    # metric file already exists, so now we merely append to the existing file. We need a seperate opener, as otherwise we would overwrite the file\n","    else:\n","        with open(logging_for_graphs_path, 'a', encoding='utf-8') as logging_appending:\n","            logging_appending.write(f'{evaluation_results} \\n')\n","\n","    #During training we can see the intermediary results, however Bartscore, Bertscore and Perplexity, make it far mor difficult to read. Tensorboard also ignores these outputs.\n","    #Therefore we only give bleu, rouge and meteor back to the trainer for logging. We do not lose any results, as we store the total results in a text file                \n","    return {\"blue_output\": bleu_output, \"rouge_output\": rouge_output, \"meteor_results\": meteor_output}\n","\n","\n","############################################################################## End Evaluation Section######################################################################################\n","\n","############################################################################## Begin Huggingface Trainer Setup ######################################################################################\n","\n","def set_training_args(model_name, learning_rate, num_train_epochs, evaluation_strategy, generation_num_beams, generation_max_length,\n","                      gradient_accumulation_steps, per_device_train_batch_size, per_device_eval_batch_size):\n","    \"\"\"\n","    Setup the training arguments that will be used during training.\n","    \"\"\"\n","    model_dir = f\"{FLAGS['drive_path']}/Results/{model_name}\"\n","\n","    training_args = Seq2SeqTrainingArguments(\n","                output_dir=model_dir,\n","                learning_rate=learning_rate,\n","                do_eval=True, # will be set to true if evaluation strategy is set\n","                do_predict=True, #Whether to run predictions on the test set or not.\n","                num_train_epochs=num_train_epochs,\n","                evaluation_strategy= evaluation_strategy,\n","                save_strategy=evaluation_strategy,\n","                logging_strategy = evaluation_strategy,\n","                save_total_limit= FLAGS['model_save_total_limit'], # the maximum number of models to keep before deleting the oldest one\n","                predict_with_generate=True, # Whether to use generate to calculate generative metrics (ROUGE, BLEU).\n","                generation_num_beams=generation_num_beams,  #The num_beams to use on each evaluation loop when predict_with_generate=True. Will default to the num_beams value of the model configuration\n","                gradient_checkpointing=True, #\n","                fp16=FLAGS['mixed_precision'],\n","                generation_max_length=generation_max_length,\n","                gradient_accumulation_steps=gradient_accumulation_steps, #Number of updates steps to accumulate the gradients for, before performing a backward/update pass\n","                per_device_train_batch_size=per_device_train_batch_size, #The batch size per GPU/TPU core/CPU for training.\n","                per_device_eval_batch_size=per_device_eval_batch_size, #The batch size per GPU/TPU core/CPU for evaluation.\n","                optim= FLAGS['training_optimizer'], #The optimizer to use: adamw_hf, adamw_torch, adamw_apex_fused, or adafactor.\n","                report_to=\"tensorboard\",\n","                load_best_model_at_end = True, #required for early stopping callback \n","                \n","                # If doing continuous learning and retraining on different datasets, parameter below will be needed if training is continued from existing model in same output/dir. \n","                # Note that this is most often not necessary for this piece of code, as we save the model in a different location, thus the model always takes all data. But if you change this, then the parameter below is needed\n","                ignore_data_skip = True, # Added this, otherwise the model skips first 150 batches of data, however we show new data so we do not want this\n","       )\n","\n","    print('LOGGING: set_training_args DONE \\n')\n","\n","    return training_args\n","\n","\n","def get_clean_model(model_name):\n","    \"\"\"\n","    Ensures that a new, fresh model is used for finetuning\n","    \"\"\"\n","    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","    return model\n","\n","     \n","\n","def set_trainer(model_name, training_args, train_ds, val_ds, tokenizer):\n","    \"\"\"\n","    Initializes a trainer\n","    Takes in: Model name, training arguments, training dataset, validation dataset, and tokenizer\n","    Returns: Trainer instance\n","    \"\"\"\n","    clean_model = get_clean_model(model_name)\n","    #continued_model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/MscThesis/Models/WeatherV2_3of4_google_mt5-base/\")\n","\n","    data_collator = DataCollatorForSeq2Seq(tokenizer)\n","    trainer = Seq2SeqTrainer(\n","                model=clean_model,\n","                args=training_args,\n","                train_dataset=train_ds,\n","                eval_dataset=val_ds,\n","                compute_metrics=compute_metrics,\n","                data_collator = data_collator,\n","                tokenizer=tokenizer,\n","                callbacks=[EarlyStoppingCallback(early_stopping_patience=FLAGS['early_stopping_patience'])], #Earlystopping metric is by default the validation loss\n","                )\n","\n","    print('LOGGING: set_trainer DONE \\n')\n","\n","    return trainer\n","############################################################################## End Huggingface Trainer Setup ######################################################################################\n","\n","############################################################################## Begin Train and Save ######################################################################################\n","\n","\n","def train_and_save(trainer, path_model_name):\n","    logging.set_verbosity_info()\n","    trainer.train()\n","    \n","    #Continue training on a previous checkpoint\n","    #trainer.train(\"/content/drive/MyDrive/MscThesis/Models/WeatherV2_3of4_google_mt5-base/\")\n","\n","    trainer.save_model(f\"{FLAGS['drive_path']}/Models/{path_model_name}\")\n","\n","    print('LOGGING: train_and_save DONE \\n')\n","\n","############################################################################## End Train and Save ######################################################################################\n","\n","\n","############################################################################## Begin Evaluation Process ######################################################################################\n","\n","def get_saved_model(path_model_name):\n","    \"\"\"\"\n","    Retrieves the best model that was saved after fine-tuning\n","    \"\"\"\n","    saved_model_path = FLAGS['saved_model_path']\n","\n","    saved_model = AutoModelForSeq2SeqLM.from_pretrained(saved_model_path, local_files_only=True)\n","    tokenizer = AutoTokenizer.from_pretrained(saved_model_path ,local_files_only=True, add_prefix_space=True)\n","\n","    return saved_model, tokenizer\n","\n","\n","\n","def generate_predictions(saved_model, test_set):\n","    \"\"\"\n","    Generates predictions based on the test set, returns a list of predictions and the corresponding \"true\" articles\n","    \"\"\"\n","    encoded_inputs = test_set.remove_columns(\"labels\")\n","\n","    # set-up a dataloader to load in the tokenized test dataset\n","    dataloader = torch.utils.data.DataLoader(encoded_inputs,  batch_size=FLAGS['batch_size']) \n","\n","    # generate text for each batch\n","    all_predictions = []\n","    for i,batch in enumerate(dataloader):\n","        predictions = saved_model.generate(**batch, max_new_tokens = 100, do_sample=True, num_beams = 5, top_p=0.7, repetition_penalty = 1.3) \n","        all_predictions.append(predictions)\n","\n","    # flatten predictions\n","    all_predictions_flattened = [pred for preds in all_predictions for pred in preds]\n","\n","    print('LOGGING: generate_predictions DONE \\n')\n","    return all_predictions_flattened\n","\n","\n","def decode_predictions(predictions, tokenizer):\n","    \"\"\"\n","    Decode the predictions made by the model\n","    \"\"\"\n","    decoded_predictions = []\n","\n","    for iteration, prediction in enumerate(predictions):\n","        decoded_predictions.append((tokenizer.decode(prediction,skip_special_tokens=True)))\n","\n","    print('LOGGING: decode_predictions DONE \\n')\n","\n","    return decoded_predictions\n","\n","\n","\n","def evaluate_test_set(path_model_name, test_set, true_articles_test, test_rdf_input):\n","    \"\"\"\n","    Transforms test set, retrieves predictions, and evaluates these predictions\n","    \"\"\"\n","    saved_model, saved_tokenizer = get_saved_model(path_model_name)\n","\n","    predictions = generate_predictions(saved_model, test_set)\n","\n","    #decode the predictions in preperation of evaluation\n","    decoded_test_predictions = decode_predictions(predictions, saved_tokenizer)\n","\n","    #calculate the evaluation metrics on the predictions\n","    bleu_output, rouge_output, meteor_output, perp_output,  bertscore_output, bart_scores_output = evaluate_texts(decoded_test_predictions, true_articles_test)\n","\n","    ## Huggingsface trainer requires a dict if multiple metrics are used\n","    evaluation_results = {\"blue_output\": bleu_output, \"rouge_output\": rouge_output, \"meteor_results\": meteor_output, \"perp_output\": perp_output, \n","                           \"bertscore_output\": bertscore_output, \"bart_scores_output\": bart_scores_output}\n","\n","    log_results(path_model_name, evaluation_results)\n","\n","    ##Additional PARENT evaluation\n","    tables = test_rdf_input\n","    references = true_articles_test\n","    generations = decoded_test_predictions\n","    parent_attempt(path_model_name, generations, references, tables)\n","    \n","    return evaluation_results\n","\n","\n","def write_to_text_parent(path_model_name, decoded_predictions, true_articles, rdfs):\n","    \"\"\"\n","    Parent script requires text files, so we create them here\n","    \"\"\"\n","\n","    with open(f\"{FLAGS['drive_path']}/Parent_test/{path_model_name}_true_articles.txt\", 'w', encoding='utf-8') as f:\n","        for articles in true_articles:\n","            f.write(f'{articles} \\n')\n","\n","    with open(f\"{FLAGS['drive_path']}/Parent_test/{path_model_name}_decode_predictions.txt\", 'w', encoding='utf-8') as f:\n","        for predictions in decoded_predictions:\n","            f.write(f'{predictions} \\n')\n","\n","    with open(f\"{FLAGS['drive_path']}/Parent_test/{path_model_name}_rdfs.txt\", 'w', encoding='utf-8') as f:\n","        for pairs in rdfs:\n","            f.write(f'{pairs} \\n')\n","\n","\n","def prepare_inputs_parent(RDFs):\n","    \"\"\"\n","    Cleans the RDF pairs and transforms them in the proper format so that the parent module can calculate with it.\n","    Input: RDF pairs of format \"Attribute | Value\"\n","    Returns a list of lists containing tuples --> [ [ (Attribute, Value), (Attribute, Value), (Attribute, Value)] ...]\n","    \"\"\"\n","\n","    attribute_value_pairs = []\n","\n","    for iteration, inputRDF in enumerate(RDFs):\n","        split_RDF = inputRDF.split(\", \")\n","        entry=[]\n","        for connected_pair in split_RDF:\n","            if '[' in connected_pair:\n","                connected_pair = connected_pair.replace('[', '')\n","            if ']' in connected_pair:\n","                connected_pair = connected_pair.replace(']', '')\n","            if '_' in connected_pair:\n","                connected_pair = connected_pair.replace('_', ' ')\n","            split_pair = tuple(connected_pair.split(' | '))\n","            entry.append((split_pair))\n","        attribute_value_pairs.append(entry)\n","    return attribute_value_pairs\n","\n","\n","def parent_attempt(path_model_name, generations, references, rdfs):\n","    \"\"\"\n","    The Parent metric needs special treatment, as it only accepts specific inputs and file types.\n","    \"\"\"\n","    prepared_rdfs = prepare_inputs_parent(rdfs)\n","    write_to_text_parent(path_model_name, generations, references, prepared_rdfs)\n","\n","    !python -i f\"{FLAGS['drive_path']}/Evaluation_code/Parent.py\" --references f\"{FLAGS['drive_path']}/Parent_test/{path_model_name}_true_articles.txt\" \\\n","                                                     --generations f\"{FLAGS['drive_path']}/Parent_test/{path_model_name}_decode_predictions.txt\"  \\\n","                                                     --tables f\"{FLAGS['drive_path']}/Parent_test/{path_model_name}_rdfs.txt\"\n","\n","def log_results(path_model_name, results):\n","    with open(f\"{FLAGS['drive_path']}/Logging_TestSet_Results/{path_model_name}_logResults.json\", 'w') as convert_file:\n","        convert_file.write(json.dumps(results))\n","\n","############################################################################## End Evaluation Process ######################################################################################\n","\n","############################################################################## Begin Full fine-tune setup######################################################################################\n","\n","def fine_tune_model(model_name):\n","    # ensure cuda compatability\n","    ensure_cuda_compatability()\n","\n","    # I instantiate the tokenizer as a global variable, as the .map function in transform_datasets was not working properly. \n","    # This should not be an issue, as the tokenizer remains consistent during training and evaluation.\n","    global tokenizer\n","    global path_model_name\n","\n","    model, tokenizer = get_saved_model(FLAGS['path_model_name'])\n","\n","    entire_dataset = load_CACAPO_data()\n","    \n","    test_ds, true_articles_test, test_rdf_inputs =  transform_datasets(entire_dataset)\n","\n","    training_args = set_training_args(model_name=model_name, learning_rate = FLAGS['learning_rate'], \n","                                     num_train_epochs = FLAGS['num_epochs'], evaluation_strategy = FLAGS['training_strategy'], generation_num_beams=FLAGS['generation_num_beams'], \n","                                     generation_max_length = FLAGS['generation_max_length'], gradient_accumulation_steps = FLAGS['gradient_accumulation_steps'], \n","                                     per_device_train_batch_size= FLAGS['batch_size'] , per_device_eval_batch_size= FLAGS['batch_size'] )\n","\n","    trainer = set_trainer(model_name, training_args, train_ds, val_ds, tokenizer)\n","\n","    # Both mt5 and T5-dutch have / in their name, which makes pathing more chaotic\n","    if '/' in model_name:\n","        path_model_name = model_name.replace('/', '_')\n","    elif '-' in model_name:\n","        path_model_name = model_name.replace('-', '_')\n","\n","    ## Finally fine-tune the model and save it\n","    train_and_save(trainer, path_model_name)\n","\n","    testset_evaluation_results = evaluate_test_set( path_model_name, test_ds, true_articles_test, test_rdf_inputs)\n","\n","    return testset_evaluation_results\n","\n","\n","############################################################################## End Full fine-tune setup######################################################################################\n","\n","\n","# Start training processes\n","def main(flags):\n","    global FLAGS\n","    global model_name\n","    \n","    FLAGS = flags\n","    results = fine_tune_model(FLAGS['model_name'])"],"metadata":{"id":"QhyrpLGu4nU5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["main(FLAGS)"],"metadata":{"id":"SSvJrTJV-y-k","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8009f804cc3c45b7871d3ed29ab7bf90","784e7d36ee9440db98217582ddb4e34d","eb24ab24cc074b298f6df57896bdea5c","2f3a1b9ec9f144c18d867dc8c1288b4b","1dac2965045a49f6ac6e78fc5cfe1142","16186d3ce0af4d7396f2f7765aa1a277","92ee634881b043aa8562f7a5410ac54f","5f207ea0ed874b0983c3ab06c01c6161","c3092d08b6a14d1a9ae5a8f48376d9be","d1f37c86957e4fabb5ceeeb032bf0750","93367cca03034777bfc9ceba20f49832","9ffb904ec46d4f3a9236ec21424b5e6e","7c47ef57b00b4171bc5a7edbff32f79d","2e9a09095b714a6a8f9c9475c1000049","12897725c18a42d7bfd24a6de9bb4eb5","1f0386398fb7448d8514503fff16ce8a","ed212207d09e49b797f63ce1baa119c9","ded278b9c5734363b58e347e504260c6","50233955d241449f86a03ef7bcaa4f41","253cff73e91b40b1a0e4924c4839fbd4","058f6cb2ee594c2dbe88db9c61e71336","5adada33dbc4467a98736167df413b2f","28c9ce02fd314134bcb2e2aff474f8f4","a65771652cad4ec0880afa0155493716","630cd8402e844904bf6866fb0c301374","6eef9cb0993e4c51afa0f68f32954a80","14bc044df1d54e15b07e5ae14be168e3","6a3393c9f09c42669269d7e7a1e5d792","5a84ed738c204215b079ec803c0b7a9e","56794b81075c471d88ebfb75d579fb90","3a08baf0ab2d415a9b601d85a3b9ce5d","be39042aa40a4e458010acbc6d9dadfe","94ec3de96787413087a6b33484871fc0"]},"outputId":"ebde7751-8685-4a4c-f9c6-e0aea5ac27ba","executionInfo":{"status":"ok","timestamp":1675885548269,"user_tz":-60,"elapsed":1372273,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Torch version: 1.13.1+cu116\n","Cuda version: 11.6\n","Cudnn version: 8302\n","Is cuda available: True\n","Number of cuda devices: 1\n","Current default device: 0\n","First cuda device: <torch.cuda.device object at 0x7ff3c8f32f10>\n","Name of the first cuda device: NVIDIA A100-SXM4-40GB\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Using custom data configuration Improved Parent Testing-197d60056c88a34a\n","WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/Improved Parent Testing-197d60056c88a34a/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8009f804cc3c45b7871d3ed29ab7bf90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ffb904ec46d4f3a9236ec21424b5e6e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["LOGGING: transform_datasets DONE \n","\n","LOGGING: generate_predictions DONE \n","\n","LOGGING: decode_predictions DONE \n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-3-e7bfc62f03a0>:111: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  bleu = datasets.load_metric(\"bleu\")\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["LOGGING: load_eval_metrics DONE \n","\n","\n"," LOGGING: Calculating Blue\n","\n"," LOGGING: Calculating Rouge\n","\n"," LOGGING: Calculating Meteor\n","\n"," LOGGING: Calculating Perplexity\n"]},{"output_type":"stream","name":"stderr","text":["Using pad_token, but it is not set yet.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/24 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28c9ce02fd314134bcb2e2aff474f8f4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"," LOGGING: Calculating Bertscore\n","\n"," LOGGING: Calculating Bartscore\n","\n"," LOGGING: Done calculations\n","python3: can't open file 'f/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py': [Errno 2] No such file or directory\n",">>> \n","\n","KeyboardInterrupt\n",">>> ^C\n"]}]},{"cell_type":"markdown","source":["# PARENT Value generations"],"metadata":{"id":"muDG77MVy7G9"}},{"cell_type":"markdown","source":["#### Base good"],"metadata":{"id":"nrJkT3-LBPQm"}},{"cell_type":"code","source":["!python -i \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\" \\\n","            --references \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Base/Improved_Parent_test_google_mt5-base_true_articles.txt\" \\\n","            --generations \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Base/Improved_Parent_test_google_mt5-base_decode_predictions.txt\"  \\\n","            --tables \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Base/Improved_Parent_test_google_mt5-base_rdfs.txt\""],"metadata":{"id":"7-vePpZg_5Ij","executionInfo":{"status":"ok","timestamp":1676556328279,"user_tz":-60,"elapsed":36503,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}},"outputId":"814c2f68-fbaf-4a99-cf32-31be0ebe3c74","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-16 14:04:52.622920: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 14:04:52.623025: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 14:04:52.623044: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","sum(precisions):  339.3934664047637    len(precisions  380)\n","sum(recalls):  119.87687802221485    len(recalls) 380)\n","sum(all_f_scores) :  149.59087501001386    len(all_f_scores)  380)\n","I0216 14:04:55.769519 140309656155968 Parent.py:571] Evaluated 380 examples.\n","I0216 14:04:55.769849 140309656155968 Parent.py:572] Precision = 0.8931 Recall = 0.3155 F-score = 0.3937\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\", line 591, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","SystemExit\n",">>> \n","KeyboardInterrupt\n",">>> ^C\n"]}]},{"cell_type":"markdown","source":["#### Base poor"],"metadata":{"id":"OWSh2eCzBSmF"}},{"cell_type":"code","source":["!python -i \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\" \\\n","            --references \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Base model/Poor/Base_model_poor_google_mt5-base_true_articles.txt\" \\\n","            --generations \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Base model/Poor/Base_model_poor_google_mt5-base_decode_predictions.txt\"  \\\n","            --tables \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Base model/Poor/Base_model_poor_google_mt5-base_rdfs.txt\""],"metadata":{"id":"9mNruiCuBNo2","executionInfo":{"status":"ok","timestamp":1676556370342,"user_tz":-60,"elapsed":16839,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}},"outputId":"d8cd1c0f-7f45-4492-c032-bc0e0b176884","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-16 14:05:54.391824: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 14:05:54.391928: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 14:05:54.391951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","sum(precisions):  248.0893484059181    len(precisions  380)\n","sum(recalls):  22.9782212815476    len(recalls) 380)\n","sum(all_f_scores) :  28.73009005219199    len(all_f_scores)  380)\n","I0216 14:05:56.850828 140386567505728 Parent.py:571] Evaluated 380 examples.\n","I0216 14:05:56.851159 140386567505728 Parent.py:572] Precision = 0.6529 Recall = 0.0605 F-score = 0.0756\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\", line 591, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","SystemExit\n",">>> \n","\n","KeyboardInterrupt\n",">>> ^C\n"]}]},{"cell_type":"markdown","source":["#### Augmented good"],"metadata":{"id":"yOYDUEiNBT8Y"}},{"cell_type":"code","source":["!python -i \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\" \\\n","            --references \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Augmented/Aug_improved_google_mt5-base_true_articles.txt\" \\\n","            --generations \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Augmented/Aug_improved_google_mt5-base_decode_predictions.txt\"  \\\n","            --tables \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Augmented/Improved_Parent_test_google_mt5-base_rdfs.txt\""],"metadata":{"id":"qkC2Osk_BNmg","executionInfo":{"status":"ok","timestamp":1676556224301,"user_tz":-60,"elapsed":60236,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}},"outputId":"7314a0ee-9d0f-45f5-afbb-4651fc568f12","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-16 14:02:44.739368: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 14:02:44.739480: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 14:02:44.739502: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","sum(precisions):  328.1906655177836    len(precisions  380)\n","sum(recalls):  109.25244749898475    len(recalls) 380)\n","sum(all_f_scores) :  136.49295113985542    len(all_f_scores)  380)\n","I0216 14:02:48.712801 139956158285632 Parent.py:571] Evaluated 380 examples.\n","I0216 14:02:48.713135 139956158285632 Parent.py:572] Precision = 0.8637 Recall = 0.2875 F-score = 0.3592\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\", line 591, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","SystemExit\n",">>> \n","KeyboardInterrupt\n",">>> ^C\n"]}]},{"cell_type":"markdown","source":["#### Augmented poor\n"],"metadata":{"id":"eYDLNUNIBVUx"}},{"cell_type":"code","source":["!python -i \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\" \\\n","            --references \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Augmented_model/Poor/Augmented_poor_test_google_mt5-base_true_articles.txt\" \\\n","            --generations \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Augmented_model/Poor/Augmented_poor_test_google_mt5-base_decode_predictions.txt\"  \\\n","            --tables \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Augmented_model/Poor/Augmented_poor_test_google_mt5-base_rdfs.txt\""],"metadata":{"id":"LZFnzjfABNjw","executionInfo":{"status":"ok","timestamp":1676556160766,"user_tz":-60,"elapsed":50185,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}},"outputId":"6d18c9c7-05b6-4a17-c5a0-58ab8020aec8","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-16 14:01:51.509110: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 14:01:51.509208: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 14:01:51.509225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","sum(precisions):  245.35758638302747    len(precisions  380)\n","sum(recalls):  20.963219653283073    len(recalls) 380)\n","sum(all_f_scores) :  26.198779139869437    len(all_f_scores)  380)\n","I0216 14:01:55.082578 139755701761856 Parent.py:571] Evaluated 380 examples.\n","I0216 14:01:55.082922 139755701761856 Parent.py:572] Precision = 0.6457 Recall = 0.0552 F-score = 0.0689\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\", line 591, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","SystemExit\n",">>> \n","\n","KeyboardInterrupt\n",">>> \n","^C\n"]}]},{"cell_type":"markdown","source":["#### Elongated good"],"metadata":{"id":"W7dQ9f-vBXFa"}},{"cell_type":"code","source":["!python -i \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\" \\\n","            --references \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Elongated/Elongated_Improved_google_mt5-base_true_articles.txt\" \\\n","            --generations \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Elongated/Elongated_Improved_google_mt5-base_decode_predictions.txt\"  \\\n","            --tables \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Elongated/Improved_Parent_test_google_mt5-base_rdfs.txt\""],"metadata":{"id":"k-wCAAg4BNhM","executionInfo":{"status":"ok","timestamp":1676556102543,"user_tz":-60,"elapsed":51035,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}},"outputId":"57d34abf-708a-47d3-aa54-a3704fb75f0c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-16 14:00:52.426004: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 14:00:52.426119: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 14:00:52.426139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","sum(precisions):  347.41226204618    len(precisions  380)\n","sum(recalls):  125.28811934754238    len(recalls) 380)\n","sum(all_f_scores) :  154.61747811621265    len(all_f_scores)  380)\n","I0216 14:00:56.123008 140385501448000 Parent.py:571] Evaluated 380 examples.\n","I0216 14:00:56.123364 140385501448000 Parent.py:572] Precision = 0.9142 Recall = 0.3297 F-score = 0.4069\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\", line 591, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","SystemExit\n",">>> \n","KeyboardInterrupt\n",">>> ^C\n"]}]},{"cell_type":"markdown","source":["#### Elongated poor"],"metadata":{"id":"ms6WOTiPBZ4c"}},{"cell_type":"code","source":["!python -i \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\" \\\n","            --references \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Elongated_Model/Poor/google_mt5-base_true_articles.txt\" \\\n","            --generations \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Elongated_Model/Poor/google_mt5-base_decode_predictions.txt\"  \\\n","            --tables \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Elongated_Model/Poor/google_mt5-base_rdfs.txt\""],"metadata":{"id":"dKMJDLPKBbWz","executionInfo":{"status":"ok","timestamp":1676556038657,"user_tz":-60,"elapsed":68723,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}},"outputId":"c291a65b-0d66-4dda-9a0f-4649f3bfa6ee","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-16 13:59:30.777004: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 13:59:30.777115: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 13:59:30.777135: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","sum(precisions):  251.08540937985896    len(precisions  380)\n","sum(recalls):  19.359979556410078    len(recalls) 380)\n","sum(all_f_scores) :  24.25166169109174    len(all_f_scores)  380)\n","I0216 13:59:34.504665 139663418181440 Parent.py:571] Evaluated 380 examples.\n","I0216 13:59:34.505154 139663418181440 Parent.py:572] Precision = 0.6608 Recall = 0.0509 F-score = 0.0638\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\", line 591, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","SystemExit\n",">>> \n","\n","KeyboardInterrupt\n",">>> \n","^C\n"]}]},{"cell_type":"markdown","source":["#### Differences in Dutch and English for Parent"],"metadata":{"id":"p7XySzwXP-5V"}},{"cell_type":"markdown","source":["##### Elongated Subset"],"metadata":{"id":"MQyxHyteQz-1"}},{"cell_type":"code","source":["!python -i \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\" \\\n","            --references \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Elongated/Elongated Language Split/NL/True_articles_improved_NL.txt\" \\\n","            --generations \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Elongated/Elongated Language Split/NL/Generations_improved_NL.txt\"  \\\n","            --tables \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Elongated/Elongated Language Split/NL/RDF_Improved_NL.txt\""],"metadata":{"id":"nqfohROBhdt-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676583322701,"user_tz":-60,"elapsed":14199,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}},"outputId":"ab4e1335-7526-4323-8e29-a1e4761a5024"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-16 21:35:09.000237: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 21:35:09.000346: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 21:35:09.000364: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","sum(precisions):  181.34627213984146    len(precisions  196)\n","sum(recalls):  67.90919578304629    len(recalls) 196)\n","sum(all_f_scores) :  82.74577243960334    len(all_f_scores)  196)\n","I0216 21:35:12.711636 140382747481920 Parent.py:571] Evaluated 196 examples.\n","I0216 21:35:12.711983 140382747481920 Parent.py:572] Precision = 0.9252 Recall = 0.3465 F-score = 0.4222\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\", line 591, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","SystemExit\n",">>> \n","\n","KeyboardInterrupt\n",">>> ^C\n"]}]},{"cell_type":"code","source":["!python -i \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\" \\\n","            --references \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Elongated/Elongated Language Split/Engels/True_articles_improved_ENG.txt\" \\\n","            --generations \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Elongated/Elongated Language Split/Engels/Generations_improved_ENG.txt\"  \\\n","            --tables \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Elongated/Elongated Language Split/Engels/RDF_improved_ENG.txt\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jWIt9GL8JbB1","executionInfo":{"status":"ok","timestamp":1676583281611,"user_tz":-60,"elapsed":13384,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}},"outputId":"98f51978-f22d-4797-c3b7-4400d2cb55b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-16 21:34:28.658749: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 21:34:28.658960: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 21:34:28.658980: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","sum(precisions):  166.0659899063384    len(precisions  184)\n","sum(recalls):  57.378923564496084    len(recalls) 184)\n","sum(all_f_scores) :  71.87170567660935    len(all_f_scores)  184)\n","I0216 21:34:34.091015 139884549666624 Parent.py:571] Evaluated 184 examples.\n","I0216 21:34:34.091451 139884549666624 Parent.py:572] Precision = 0.9025 Recall = 0.3118 F-score = 0.3906\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\", line 591, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","SystemExit\n",">>> \n","\n","KeyboardInterrupt\n",">>> \n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","source":["!python -i \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\" \\\n","            --references \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Base/Language_change/Base_reference_parent_ENG.txt\" \\\n","            --generations \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Base/Language_change/Base_generations_parent_ENG.txt\"  \\\n","            --tables \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Base/Language_change/Base_rdf_parent_ENG.txt\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1UvOvbDgQ42x","executionInfo":{"status":"ok","timestamp":1676585799562,"user_tz":-60,"elapsed":11166,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}},"outputId":"4d93b521-0ff9-43ed-cb81-20d4c48f8c72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-16 22:16:28.444988: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 22:16:28.445105: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 22:16:28.445124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","sum(precisions):  162.4236033574828    len(precisions  184)\n","sum(recalls):  56.86800907902294    len(recalls) 184)\n","sum(all_f_scores) :  71.83224363806865    len(all_f_scores)  184)\n","I0216 22:16:33.818626 139724901484352 Parent.py:571] Evaluated 184 examples.\n","I0216 22:16:33.818982 139724901484352 Parent.py:572] Precision = 0.8827 Recall = 0.3091 F-score = 0.3904\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\", line 591, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","SystemExit\n",">>> \n","\n","KeyboardInterrupt\n",">>> ^C\n"]}]},{"cell_type":"code","source":["!python -i \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\" \\\n","            --references \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Base/Language_change/Base_reference_parent_NL.txt\" \\\n","            --generations \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Base/Language_change/Base_generations_parent_NL.txt\"  \\\n","            --tables \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Base/Language_change/Base_rdf_parent_NL.txt\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8u1gbxVCQ4ze","executionInfo":{"status":"ok","timestamp":1676585810970,"user_tz":-60,"elapsed":11410,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}},"outputId":"b709c26c-23c1-41ec-9f3e-0a26f0b1df31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-16 22:16:39.602112: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 22:16:39.602255: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 22:16:39.602277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","sum(precisions):  176.9698630472812    len(precisions  196)\n","sum(recalls):  63.008868943191956    len(recalls) 196)\n","sum(all_f_scores) :  77.75863137194513    len(all_f_scores)  196)\n","I0216 22:16:44.972071 140159369832256 Parent.py:571] Evaluated 196 examples.\n","I0216 22:16:44.972404 140159369832256 Parent.py:572] Precision = 0.9029 Recall = 0.3215 F-score = 0.3967\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\", line 591, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","SystemExit\n",">>> \n","\n","KeyboardInterrupt\n",">>> ^C\n"]}]},{"cell_type":"code","source":["!python -i \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\" \\\n","            --references \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Augmented/Language split/Aug_reference_parent_Eng.txt\" \\\n","            --generations \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Augmented/Language split/Aug_generations_parent_Eng.txt\"  \\\n","            --tables \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Augmented/Language split/Aug_good_parent_ENG.txt\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8gpovziQ4ms","executionInfo":{"status":"ok","timestamp":1676585822032,"user_tz":-60,"elapsed":11063,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}},"outputId":"9c406e65-a77b-4eec-ce22-3b11a1de2838"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-16 22:16:51.007870: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 22:16:51.007994: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 22:16:51.008013: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","sum(precisions):  152.77040166989386    len(precisions  184)\n","sum(recalls):  50.36284367263732    len(recalls) 184)\n","sum(all_f_scores) :  64.00356986638603    len(all_f_scores)  184)\n","I0216 22:16:55.958149 140229007349568 Parent.py:571] Evaluated 184 examples.\n","I0216 22:16:55.958490 140229007349568 Parent.py:572] Precision = 0.8303 Recall = 0.2737 F-score = 0.3478\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\", line 591, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","SystemExit\n",">>> \n","\n","KeyboardInterrupt\n",">>> ^C\n"]}]},{"cell_type":"code","source":["!python -i \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\" \\\n","            --references \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Augmented/Language split/Aug_reference_NL.txt\" \\\n","            --generations \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Augmented/Language split/Aug_generations_parent_Nl.txt\"  \\\n","            --tables \"/content/drive/MyDrive/MscThesis/Parent_test/Experiment_Elongated_Poor_v_Good/Improved testing/Augmented/Language split/Aug_good_parent_NL.txt\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P7p5go2IQ4W4","executionInfo":{"status":"ok","timestamp":1676585832118,"user_tz":-60,"elapsed":10088,"user":{"displayName":"Simon van de Fliert","userId":"02670396575065469976"}},"outputId":"4653e182-ccb7-4a91-ee10-d1260ca47c10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-16 22:17:01.779703: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 22:17:01.779834: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-16 22:17:01.779856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","sum(precisions):  175.42026384789006    len(precisions  196)\n","sum(recalls):  58.889603826347454    len(recalls) 196)\n","sum(all_f_scores) :  72.48938127346942    len(all_f_scores)  196)\n","I0216 22:17:06.579260 140143403939648 Parent.py:571] Evaluated 196 examples.\n","I0216 22:17:06.579537 140143403939648 Parent.py:572] Precision = 0.8950 Recall = 0.3005 F-score = 0.3698\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MscThesis/Evaluation_code/Parent.py\", line 591, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","SystemExit\n",">>> \n","\n","KeyboardInterrupt\n",">>> ^C\n"]}]}]}